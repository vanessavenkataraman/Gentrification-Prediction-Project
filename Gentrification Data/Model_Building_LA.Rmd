---
title: "Modeling for Los Angeles dataset"
date: "2022-12-22"
geometry: margin=1.5cm
output:
  word_document: default
  html_document: default
---
**Description:** This script is used to train, test and interpret the machine learning models for the tracts of the Los Angeles MSA.

<br>

**The datasets used in this script are the following:**

* la_training_data.csv - This file is the training data for the Los Angeles MSA

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# clearing the workspace
rm(list=ls(all=TRUE))

# loading all the required libraries
library(readr, quietly = T)
library(data.table, quietly = T)
library(dplyr, quietly = T)
library(caret, quietly = T)
library(randomForest, quietly = T)
library(smotefamily, quietly = T)
```

```{r}
# reading in the training dataset
la_data = read.csv("la_training_data.csv")

# converting the output variable to a factor
la_data$Gentrified <- as.factor(la_data$Gentrified)
```

```{r}
# creating a new column as the sum of multiple columns and dropping the individual columns
# combining the proportions of Black, American Indians, Asians and Native Hawaiian and other Pacific Islander population.
la_data['SHRNWT0'] = la_data['SHRBLK0'] + la_data['SHRAMI0'] + la_data['SHRASN0'] + la_data['SHRHIP0']
la_data <- subset(la_data, select = -c(SHRBLK0, SHRAMI0, SHRASN0, SHRHIP0))
la_data <- select(la_data, 'SHRNWT0', everything())

# viewing the training dataset
head(la_data)
```

```{r}
# normalizing the variables which are not in proportions (since proportions are already between 0 - 1)
minMax <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

la_data[c('WORKER30', 'AVWELIN0', 'AVSSI0', 'MDFAMY0', 'AVSOCS0', 'AVRETR0')] <- 
                                 lapply(la_data[c('WORKER30', 'AVWELIN0', 'AVSSI0', 'MDFAMY0', 'AVSOCS0', 'AVRETR0')], minMax)
head(la_data)
```
```{r}
# count of 0s and 1s of the output variable in the training data
print(table(la_data$Gentrified))
```

```{r}
# randomly splitting the data into training and testing sets 
set.seed(12345)
tr <- sample.int(n = nrow(la_data), size = floor(.8*nrow(la_data)), replace = FALSE)
la_data_train <- la_data[tr, ]
la_data_test <- la_data[-tr, ]
```

```{r}
# count of 0s and 1s of the output variable in the training and testing sets
print(table(la_data_train$Gentrified))
print(table(la_data_test$Gentrified))
```
**Logistic Regression**

```{r}
# fitting a logistic regression model and printing the summary of the model
logistic_model <- glm(Gentrified ~ ., data = la_data_train, family = "binomial")
summary(logistic_model)
```

```{r}
# obtaining the predictions on the testing set using the above model and printing the confusion matrix 
predlg1 <- predict(logistic_model, la_data_test, type = 'response')
predlg1 <- ifelse(predlg1 > 0.5, 1, 0)
predlg1 <- as.factor(predlg1)
confusionMatrix(predlg1, la_data_test$Gentrified, mode = 'everything', positive = '1')
```

```{r}
# sub-setting the training and testing sets with only the variables which are inferred as statistically significant from the logistic model
la_data_train <- subset(la_data_train, select = c(SHRNWT0, CHILD0, WRKSM0, POVRAT0, MDFAMY0, Gentrified))
la_data_test <- subset(la_data_test, select = c(SHRNWT0, CHILD0, WRKSM0, POVRAT0, MDFAMY0, Gentrified))
```

**Random Forest Classifier**

```{r}
# fitting a random forest classifier and printing the confusion matrix
rf1 <- randomForest(Gentrified ~ ., data=la_data_train)
predrf1 <- predict(rf1, la_data_test)
confusionMatrix(predrf1, la_data_test$Gentrified, mode = 'everything', positive = '1')
```

**Re-sampling data to balance the two classes in the output variable**

```{r}
# using ADASYN (Adaptive Synthetic Sampling) technique to generate samples of the minority class
set.seed(1234)
la_data_train_balanced <- ADAS(la_data_train[,-ncol(la_data_train)], la_data_train$Gentrified)
la_data_train_balanced <- la_data_train_balanced$data
names(la_data_train_balanced)[names(la_data_train_balanced) == 'class'] <- 'Gentrified'

# converting the output variable to a factor
la_data_train_balanced$Gentrified <- as.factor(la_data_train_balanced$Gentrified)

# count of 0s and 1s of the output variable in the new training set
table(la_data_train_balanced$Gentrified)
```

**Random Forest Classifier (using the new training dataset)**

```{r}
# fitting a random forest classifier and printing the confusion matrix
rf2 <- randomForest(Gentrified ~ ., data = la_data_train_balanced)
predrf2 <- predict(rf2, la_data_test)
confusionMatrix(predrf2, la_data_test$Gentrified, mode = 'everything', positive = '1')
```